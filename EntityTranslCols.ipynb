{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment Entity DataFrame with Translation Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is using paid translation service from Googld Cloud Translate\n",
    "Put the path of google application credential here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: GOOGLE_APPLICATION_CREDENTIALS=../GOOGLE_APPLICATION_CREDENTIALS/AIDA-0cf5a4cb6e90.json\n"
     ]
    }
   ],
   "source": [
    "%env GOOGLE_APPLICATION_CREDENTIALS=../GOOGLE_APPLICATION_CREDENTIALS/AIDA-0cf5a4cb6e90.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import html\n",
    "import sys\n",
    "from ast import literal_eval as make_tuple\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Entity Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "repo = 'dryrun3-gaia2v1-vision-ta2'\n",
    "version = '001'\n",
    "store_data_dir = '/nas/home/jchen/store_data/' + repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>source</th>\n",
       "      <th>targets</th>\n",
       "      <th>target_scores</th>\n",
       "      <th>fbid</th>\n",
       "      <th>fbid_score_avg</th>\n",
       "      <th>fbid_score_max</th>\n",
       "      <th>wikidata</th>\n",
       "      <th>wiki_label_en</th>\n",
       "      <th>wiki_label_ru</th>\n",
       "      <th>wiki_label_uk</th>\n",
       "      <th>wiki_alias_en</th>\n",
       "      <th>wiki_alias_ru</th>\n",
       "      <th>wiki_alias_uk</th>\n",
       "      <th>lang</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.isi.edu/gaia/entities/3a91d6b4-1e0d...</td>\n",
       "      <td>ldcOnt:GPE</td>\n",
       "      <td>(–ì–≤–∏–Ω–µ–µ,)</td>\n",
       "      <td>HC00007OW</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ru</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.isi.edu/gaia/entities/15dc8f2c-b83e...</td>\n",
       "      <td>ldcOnt:GPE.Country.Country</td>\n",
       "      <td>(–ì–∞–º–±–∏–∏, –ì–∞–º–±–∏–∏, –ì–∞–º–±–∏–∏)</td>\n",
       "      <td>HC00007OW</td>\n",
       "      <td>(LDC2019E43:2409223, LDC2019E43:2413451, LDC20...</td>\n",
       "      <td>(0.0014, 0.9935, 0.0014)</td>\n",
       "      <td>(m.0hdx8,)</td>\n",
       "      <td>(0.6491159797,)</td>\n",
       "      <td>(0.6491159797,)</td>\n",
       "      <td>(http://www.wikidata.org/entity/Q1005,)</td>\n",
       "      <td>(Gambia,)</td>\n",
       "      <td>(–ì–∞–º–±–∏—è,)</td>\n",
       "      <td>(–ì–∞–º–±—ñ—è,)</td>\n",
       "      <td>((gm, GAM, üá¨üá≤, Islamic Republic of the Gambia,...</td>\n",
       "      <td>((–†–µ—Å–ø—É–±–ª–∏–∫–∞ –ì–∞–º–±–∏—è,),)</td>\n",
       "      <td>((–†–µ—Å–ø—É–±–ª—ñ–∫–∞ –ì–∞–º–±—ñ—è,),)</td>\n",
       "      <td>ru</td>\n",
       "      <td>((Gambia ,),)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>http://www.isi.edu/gaia/entities/4bd2e87f-78b3...</td>\n",
       "      <td>ldcOnt:GPE.Country.Country</td>\n",
       "      <td>(–ò—Ç–∞–ª–∏—é, –ò—Ç–∞–ª–∏—é, –ò—Ç–∞–ª–∏—é, –ò—Ç–∞–ª–∏—é, –ò—Ç–∞–ª–∏—é, –ò—Ç–∞–ª–∏...</td>\n",
       "      <td>HC00007OW</td>\n",
       "      <td>(LDC2019E43:3170325, LDC2019E43:3175395, LDC20...</td>\n",
       "      <td>(0.0001456717, 0.9994537, 0.0001456717, 0.0002...</td>\n",
       "      <td>(m.03rjj,)</td>\n",
       "      <td>(0.8315719711,)</td>\n",
       "      <td>(1.0,)</td>\n",
       "      <td>(http://www.wikidata.org/entity/Q38,)</td>\n",
       "      <td>(Italy,)</td>\n",
       "      <td>(–ò—Ç–∞–ª–∏—è,)</td>\n",
       "      <td>(–Ü—Ç–∞–ª—ñ—è,)</td>\n",
       "      <td>((ITA, it, IT, üáÆüáπ, Italia, Italian Republic),)</td>\n",
       "      <td>((–ò—Ç–∞–ª—å—è–Ω—Å–∫–∞—è –†–µ—Å–ø—É–±–ª–∏–∫–∞,),)</td>\n",
       "      <td>((),)</td>\n",
       "      <td>ru</td>\n",
       "      <td>((Italy ,),)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>http://www.isi.edu/gaia/entities/08174a18-570b...</td>\n",
       "      <td>ldcOnt:GPE</td>\n",
       "      <td>(–ø—Ä–æ–≤–∏–Ω—Ü–∏–∏ –¢—É—Ä–∏–Ω–∞,)</td>\n",
       "      <td>HC00007OW</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ru</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>http://www.isi.edu/gaia/entities/16c350bb-352d...</td>\n",
       "      <td>ldcOnt:VAL</td>\n",
       "      <td>None</td>\n",
       "      <td>HC00007OW</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ru</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    e  \\\n",
       "0   http://www.isi.edu/gaia/entities/3a91d6b4-1e0d...   \n",
       "4   http://www.isi.edu/gaia/entities/15dc8f2c-b83e...   \n",
       "7   http://www.isi.edu/gaia/entities/4bd2e87f-78b3...   \n",
       "17  http://www.isi.edu/gaia/entities/08174a18-570b...   \n",
       "18  http://www.isi.edu/gaia/entities/16c350bb-352d...   \n",
       "\n",
       "                          type  \\\n",
       "0                   ldcOnt:GPE   \n",
       "4   ldcOnt:GPE.Country.Country   \n",
       "7   ldcOnt:GPE.Country.Country   \n",
       "17                  ldcOnt:GPE   \n",
       "18                  ldcOnt:VAL   \n",
       "\n",
       "                                                 name     source  \\\n",
       "0                                           (–ì–≤–∏–Ω–µ–µ,)  HC00007OW   \n",
       "4                            (–ì–∞–º–±–∏–∏, –ì–∞–º–±–∏–∏, –ì–∞–º–±–∏–∏)  HC00007OW   \n",
       "7   (–ò—Ç–∞–ª–∏—é, –ò—Ç–∞–ª–∏—é, –ò—Ç–∞–ª–∏—é, –ò—Ç–∞–ª–∏—é, –ò—Ç–∞–ª–∏—é, –ò—Ç–∞–ª–∏...  HC00007OW   \n",
       "17                                (–ø—Ä–æ–≤–∏–Ω—Ü–∏–∏ –¢—É—Ä–∏–Ω–∞,)  HC00007OW   \n",
       "18                                               None  HC00007OW   \n",
       "\n",
       "                                              targets  \\\n",
       "0                                                None   \n",
       "4   (LDC2019E43:2409223, LDC2019E43:2413451, LDC20...   \n",
       "7   (LDC2019E43:3170325, LDC2019E43:3175395, LDC20...   \n",
       "17                                               None   \n",
       "18                                               None   \n",
       "\n",
       "                                        target_scores        fbid  \\\n",
       "0                                                None        None   \n",
       "4                            (0.0014, 0.9935, 0.0014)  (m.0hdx8,)   \n",
       "7   (0.0001456717, 0.9994537, 0.0001456717, 0.0002...  (m.03rjj,)   \n",
       "17                                               None        None   \n",
       "18                                               None        None   \n",
       "\n",
       "     fbid_score_avg   fbid_score_max                                 wikidata  \\\n",
       "0              None             None                                     None   \n",
       "4   (0.6491159797,)  (0.6491159797,)  (http://www.wikidata.org/entity/Q1005,)   \n",
       "7   (0.8315719711,)           (1.0,)    (http://www.wikidata.org/entity/Q38,)   \n",
       "17             None             None                                     None   \n",
       "18             None             None                                     None   \n",
       "\n",
       "   wiki_label_en wiki_label_ru wiki_label_uk  \\\n",
       "0           None          None          None   \n",
       "4      (Gambia,)     (–ì–∞–º–±–∏—è,)     (–ì–∞–º–±—ñ—è,)   \n",
       "7       (Italy,)     (–ò—Ç–∞–ª–∏—è,)     (–Ü—Ç–∞–ª—ñ—è,)   \n",
       "17          None          None          None   \n",
       "18          None          None          None   \n",
       "\n",
       "                                        wiki_alias_en  \\\n",
       "0                                                None   \n",
       "4   ((gm, GAM, üá¨üá≤, Islamic Republic of the Gambia,...   \n",
       "7      ((ITA, it, IT, üáÆüáπ, Italia, Italian Republic),)   \n",
       "17                                               None   \n",
       "18                                               None   \n",
       "\n",
       "                   wiki_alias_ru            wiki_alias_uk lang          label  \n",
       "0                           None                     None   ru           None  \n",
       "4        ((–†–µ—Å–ø—É–±–ª–∏–∫–∞ –ì–∞–º–±–∏—è,),)  ((–†–µ—Å–ø—É–±–ª—ñ–∫–∞ –ì–∞–º–±—ñ—è,),)   ru  ((Gambia ,),)  \n",
       "7   ((–ò—Ç–∞–ª—å—è–Ω—Å–∫–∞—è –†–µ—Å–ø—É–±–ª–∏–∫–∞,),)                    ((),)   ru   ((Italy ,),)  \n",
       "17                          None                     None   ru           None  \n",
       "18                          None                     None   ru           None  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_entity = pd.read_hdf(store_data_dir + '/entity_all_' + version + '.h5')\n",
    "df_entity = df_entity.where(pd.notnull(df_entity), None)\n",
    "has_origin = True if 'originLabel' in df_entity.columns else False\n",
    "df_entity.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the dictionaries\n",
    "Load previously generated Russian and Ukranian dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dictionary(file_path):\n",
    "    with open(file_path, 'r') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        return {row['RU/UK'].lower():row['EN'] for row in reader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ru_path = 'dictionaries/dict_ru_en.csv'\n",
    "dict_uk_path = 'dictionaries/dict_uk_en.csv'\n",
    "dict_ru = get_dictionary(dict_ru_path)\n",
    "dict_uk = get_dictionary(dict_uk_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Translation Function\n",
    "Translate a list of words. Dictionaries are used before using Google translate API (because it's fee-based). Save new translations in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_en(text):\n",
    "    try:\n",
    "        if detect(text) != 'ru' and detect(text) != 'uk':\n",
    "            return True\n",
    "    except:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def translate_words(word_list, source_lang):\n",
    "    dict_a = None\n",
    "    if source_lang.lower() == 'ru':\n",
    "        dict_a = dict_ru\n",
    "    else:\n",
    "        dict_a = dict_uk\n",
    "        \n",
    "    translations = []\n",
    "    for word in word_list:\n",
    "        translation = None\n",
    "        if is_en(word):\n",
    "            translations.append(word)\n",
    "        elif word.lower() in dict_a:\n",
    "            translations.append(dict_a[word.lower()])\n",
    "        else: # else use google translate and add to dictionary\n",
    "            print('\\r', word, end='')\n",
    "            translated = free_google_translate(word, source_lang)\n",
    "            translations.append(translated)\n",
    "            dict_a[word.lower()] = translated # write out the new dictionary??\n",
    "    return translations\n",
    "\n",
    "# free google translator\n",
    "from googletrans import Translator\n",
    "free_translator = Translator()\n",
    "def free_google_translate(text, source_lang):\n",
    "    try:\n",
    "        translation = free_translator.translate(text, src=source_lang, dest='en')\n",
    "    except:\n",
    "        return None\n",
    "    return translation.text\n",
    "    \n",
    "def free_google_translate_bulk(words, source_lang):\n",
    "    requests = list(partition_list(words, 100))\n",
    "    res = {}\n",
    "    for request in requests:\n",
    "        try:\n",
    "            translations = free_translator.translate(request, src=source_lang, dest='en')\n",
    "            for translation in translations:\n",
    "                res[translation.origin] = translation.text\n",
    "        except:\n",
    "            pass\n",
    "    return res\n",
    "\n",
    "# paid google cloud translator\n",
    "from google.cloud import translate\n",
    "google_translate_client = translate.Client()\n",
    "\n",
    "def google_translate(text, source_lang):\n",
    "    translation = google_translate_client.translate(text, source_language=source_lang, target_language='EN')\n",
    "    return html.unescape(translation['translatedText'])\n",
    "\n",
    "def google_translate_bulk(words, source_lang):\n",
    "    requests = list(partition_list(words, 100))\n",
    "    dict_a = {}\n",
    "    for request in requests:\n",
    "        translations = google_translate_client.translate(request, source_language=source_lang, target_language='EN')\n",
    "        for translation in translations:\n",
    "            dict_a[translation['input'].lower()] = html.unescape(translation['translatedText'])\n",
    "    return dict_a\n",
    "\n",
    "def partition_list(lines: list, size: int):\n",
    "    for i in range(0, len(lines), size):\n",
    "        yield lines[i:i+size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a list of strings from dataframe not in the dictionary\n",
    "Avoiding translating as we go through the dataframe, it's very slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_ru_uk(df):\n",
    "    lists = {}\n",
    "    ru = []\n",
    "    uk = []\n",
    "    for i, row in df.iterrows():\n",
    "        if row['name'] and row.lang:\n",
    "            if row.lang.lower()[:2] == 'ru':\n",
    "                ru = ru + list(row['name'])\n",
    "            elif row.lang.lower()[:2] == 'uk':\n",
    "                uk = uk + list(row['name'])\n",
    "        if row.wiki_label_ru:\n",
    "            ru = ru + list(row.wiki_label_ru)\n",
    "        if row.wiki_label_uk:\n",
    "            uk = uk + list(row.wiki_label_uk)\n",
    "        if row.wiki_alias_ru:\n",
    "            for lst in row.wiki_alias_ru:\n",
    "                if lst:\n",
    "                    ru = ru + list(lst)\n",
    "        if row.wiki_alias_uk:\n",
    "            for lst in row.wiki_alias_uk:\n",
    "                if lst:\n",
    "                    uk = uk + list(lst)\n",
    "        if has_origin and row.originLabel and row.lang:\n",
    "            if row.lang.lower()[:2] == 'ru':\n",
    "                ru = ru + list(row.originLabel)\n",
    "            elif row.lang.lower()[:2] == 'uk':\n",
    "                uk = uk + list(row.originLabel)\n",
    "    ru = list(set(ru)) # remove duplicates\n",
    "    uk = list(set(uk))\n",
    "    ru = list(w for w in ru if not is_en(w) and w.lower() not in (word.lower() for word in dict_ru))\n",
    "    uk = list(w for w in uk if not is_en(w) and w.lower() not in (word.lower() for word in dict_uk))\n",
    "    \n",
    "    lists['ru'] = list(set(ru))\n",
    "    lists['uk'] = list(set(uk))\n",
    "\n",
    "    return lists\n",
    "        \n",
    "need_transl = get_all_ru_uk(df_entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translate those not in the dictionary in bulk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ru_ext = free_google_translate_bulk(need_transl['ru'], 'RU')\n",
    "dict_ru.update(dict_ru_ext)\n",
    "dict_uk_ext = free_google_translate_bulk(need_transl['uk'], 'UK')\n",
    "dict_uk.update(dict_uk_ext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dictionary(dict_a, file):       \n",
    "    with open(file, 'w') as csvfile:\n",
    "        fieldnames = ['RU/UK', 'EN']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for k, v in dict_a.items():\n",
    "            writer.writerow({'RU/UK': k, 'EN': v})\n",
    "\n",
    "save_dictionary(dict_ru, dict_ru_path)\n",
    "save_dictionary(dict_uk, dict_uk_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The core: Adding translation columns to entity table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " —Ü–∞—Ä—Å–∫–æ–π –∏–º–ø–µ—Ä–∏–∏"
     ]
    }
   ],
   "source": [
    "def add_translation_cols(table):\n",
    "    if has_origin:\n",
    "        table[['transl_name', 'transl_label_ru', 'transl_label_uk', 'transl_alias_ru', 'transl_alias_uk', 'transl_origin_label']] = table[['name', 'lang', 'wiki_label_ru', 'wiki_label_uk', 'wiki_alias_ru', 'wiki_alias_uk', 'originLabel']].apply(get_translation_cols, axis='columns')\n",
    "    else:\n",
    "        table[['transl_name', 'transl_label_ru', 'transl_label_uk', 'transl_alias_ru', 'transl_alias_uk']] = table[['name', 'lang', 'wiki_label_ru', 'wiki_label_uk', 'wiki_alias_ru', 'wiki_alias_uk']].apply(get_translation_cols, axis='columns')\n",
    "    return table\n",
    "   \n",
    "def get_translation_cols(row):\n",
    "    transl_label = None if not row['name'] or not row.lang or row.lang.lower().startswith('en') else translate_words(list(row['name']), row.lang[:2])\n",
    "    transl_label_ru = translate_words(list(row.wiki_label_ru), 'RU') if row.wiki_label_ru else None \n",
    "    transl_label_uk = translate_words(list(row.wiki_label_uk), 'UK') if row.wiki_label_uk else None\n",
    "    transl_alias_ru = ()\n",
    "    if row.wiki_alias_ru:\n",
    "        for lst in row.wiki_alias_ru:\n",
    "            if lst:\n",
    "                transl_alias_ru = transl_alias_ru + (translate_words(list(lst), 'RU'),)\n",
    "            else:\n",
    "                transl_alias_ru = transl_alias_ru + (None,)\n",
    "    else:\n",
    "        transl_alias_ru = None\n",
    "    \n",
    "    transl_alias_uk = ()\n",
    "    if row.wiki_alias_uk:\n",
    "        for lst in row.wiki_alias_uk:\n",
    "            if lst:\n",
    "                transl_alias_uk = transl_alias_uk + (translate_words(list(lst), 'UK'),)\n",
    "            else:\n",
    "                transl_alias_uk = transl_alias_uk + (None,)\n",
    "    else:\n",
    "        transl_alias_uk = None\n",
    "    \n",
    "    if has_origin:\n",
    "        transl_origin_label = None if not row.originLabel or not row.lang or row.lang.lower().startswith('en') else translate_words(list(row.originLabel), row.lang[:2])\n",
    "        return pd.Series({'transl_name': transl_label, 'transl_label_ru': transl_label_ru, 'transl_label_uk': transl_label_uk, 'transl_alias_ru': transl_alias_ru, 'transl_alias_uk': transl_alias_uk, 'transl_origin_label': transl_origin_label})\n",
    "    else:\n",
    "        return pd.Series({'transl_name': transl_label, 'transl_label_ru': transl_label_ru, 'transl_label_uk': transl_label_uk, 'transl_alias_ru': transl_alias_ru, 'transl_alias_uk': transl_alias_uk})\n",
    "\n",
    "df_trans = add_translation_cols(df_entity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write out new entity dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out dataframe\n",
    "df_trans.to_hdf(store_data_dir + '/entity_trans_all_' + version + '.h5', 'entity', mode='w', format='fixed')\n",
    "_ = pd.read_hdf(store_data_dir + '/entity_trans_all_' + version + '.h5')\n",
    "\n",
    "# write out dataframe filtered\n",
    "# df_trans_filtered = df_trans[(~df_trans['debug'])]\n",
    "df_trans_filtered = df_trans\n",
    "df_trans_filtered.to_hdf(store_data_dir + '/entity_trans_all_filtered_' + version + '.h5', 'entity', mode='w', format='fixed')\n",
    "df_trans_filtered.to_csv(store_data_dir + '/entity_trans_all_filtered_' + version + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans = pd.read_hdf(store_data_dir + '/entity_trans_all_filtered_' + version + '.h5')\n",
    "df_trans.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dictionary(dict_ru, dict_ru_path)\n",
    "save_dictionary(dict_uk, dict_uk_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
